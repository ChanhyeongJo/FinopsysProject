# -*- coding: utf-8 -*-
"""상품 EDA 및 알고리즘 초기

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xzkEXzX-7eHsKbsgB74Yq6xMbUdb-hvW
"""

# import pandas as pd
# import re

# 우대금리_df = pd.read_csv('dfb_1금융만.csv')
# with open('조건_flat.txt', 'r', encoding='utf-8') as file:
#     condition_lines = [line.strip() for line in file.readlines() if line.strip()]

# # 조건 텍스트에서 핵심 단어 추출
# def extract_keywords(condition_text):
#     return re.findall(r'\b\w{2,}\b', condition_text)  # 두 글자 이상 단어 추출

# # 조건 키워드 딕셔너리 생성
# condition_keywords = {f"조건_{i+1}": extract_keywords(condition_lines[i]) for i in range(len(condition_lines))}

# # 조건 데이터프레임 생성
# condition_df = pd.DataFrame(list(condition_keywords.items()), columns=['조건', '핵심단어'])

# # `_조건`과 `_우대금리` 컬럼 찾기
# condition_columns = [col for col in 우대금리_df.columns if '_조건' in col and '_우대금리' not in col]
# rate_columns = [col.replace('_조건', '_우대금리') for col in condition_columns]

# # 매칭된 컬럼과 누락된 컬럼 확인
# matching_check = [(cond, rate) for cond, rate in zip(condition_columns, rate_columns) if rate in 우대금리_df.columns]
# valid_conditions = [pair[0] for pair in matching_check]  # 매칭된 `_조건` 컬럼
# valid_rates = [pair[1] for pair in matching_check]  # 매칭된 `_우대금리` 컬럼

# # 매칭된 조건-우대금리 페어를 기반으로 새로운 열 생성
# for cond_col, rate_col in zip(valid_conditions, valid_rates):
#     condition_name = cond_col.replace('_조건', '')  # `_조건`을 제거하여 새로운 열 이름 생성
#     우대금리_df[condition_name] = 우대금리_df.apply(
#         lambda row: f"1({row[rate_col]})" if pd.notna(row[cond_col]) and str(row[cond_col]).strip() else "0",
#         axis=1
#     )

# output_path = '상품_updated우대금리(0,1)_dataset.csv'
# 우대금리_df.to_csv(output_path, index=False)

# # 출력 파일 경로
# print(f"파일 저장 완료: {output_path}")



# 필요한 라이브러리 임포트
import pandas as pd
import numpy as np

# 최소값과 최대값을 합치는 함수 정의
def combine_min_max(row, min_col, max_col):
    if pd.isnull(row[min_col]) and pd.isnull(row[max_col]):
        return None
    if row[min_col] == row[max_col]:
        return str(row[min_col])  # 값이 같으면 하나의 값만 반환
    return f"{row[min_col]} ~ {row[max_col]}"  # 다르면 "최소 ~ 최대" 형식

uploaded_file_path = 'updated_우대금리_dataset.csv'
uploaded_df = pd.read_csv(uploaded_file_path)

# 계약기간 병합
if '계약기간개월수_최소구간' in uploaded_df.columns and '계약기간개월수_최대구간' in uploaded_df.columns:
    uploaded_df.insert(
        uploaded_df.columns.get_loc('계약기간개월수_최소구간'),  # 기존 최소 구간 컬럼의 위치를 기준으로 삽입
        '계약기간',
        uploaded_df.apply(
            combine_min_max, axis=1, min_col='계약기간개월수_최소구간', max_col='계약기간개월수_최대구간'
        )
    )
    # 원본 칼럼 제거
    uploaded_df.drop(columns=['계약기간개월수_최소구간', '계약기간개월수_최대구간'], inplace=True)

# 가입금액 병합
if '가입금액_최소구간' in uploaded_df.columns and '가입금액_최대구간' in uploaded_df.columns:
    uploaded_df.insert(
        uploaded_df.columns.get_loc('가입금액_최소구간'),  # 기존 최소 구간 컬럼의 위치를 기준으로 삽입
        '가입금액',
        uploaded_df.apply(
            combine_min_max, axis=1, min_col='가입금액_최소구간', max_col='가입금액_최대구간'
        )
    )
    # 원본 칼럼 제거
    uploaded_df.drop(columns=['가입금액_최소구간', '가입금액_최대구간'], inplace=True)

# 결과 저장
#uploaded_df.to_csv('processed_dataset.csv', index=False)

# 결과 확인
print(uploaded_df.head())

import pandas as pd

# 데이터 로드
processed_file_path = 'processed_dataset.csv'  # 파일 경로를 입력하세요
processed_df = pd.read_csv(processed_file_path)

# '우대금리조건여부' 이하 칼럼 드롭
if '우대금리조건여부' in processed_df.columns:
    drop_start_index = processed_df.columns.get_loc('우대금리조건여부')  # '우대금리조건여부'의 위치
    processed_df = processed_df.iloc[:, :drop_start_index]  # 해당 컬럼 이전까지 유지

# 결과 저장
processed_df.to_csv('processed_dataset_dropped.csv', index=False)

# 결과 확인
print(processed_df.head())

processed_df

processed_df.info()

# Step 1: Count how many times each combination of '은행코드', '은행명', '상품코드', '상품명' appears
count_same_product = processed_df.groupby(['은행코드', '은행명', '상품코드', '상품명']).size().reset_index(name='count')

count_same_product

# Step 2: Check if there are rows where '상품일련번호' is different for the same combination of the first 4 columns
product_with_different_serial = processed_df.groupby(['은행코드', '은행명', '상품코드', '상품명'])['상품일련번호'].nunique().reset_index(name='unique_serial_count')
product_with_different_serial = product_with_different_serial[product_with_different_serial['unique_serial_count'] > 1]
product_with_different_serial

# Check for duplicate rows based on specific columns
duplicates_specific_columns = processed_df[processed_df.duplicated(subset=['은행코드', '은행명', '상품코드', '상품명', '상품일련번호'], keep=False)]

# Count the number of duplicate rows
duplicates_specific_columns_count = duplicates_specific_columns.shape[0]

# Display the results
print(f"Number of duplicate rows based on specified columns: {duplicates_specific_columns_count}")
if duplicates_specific_columns_count > 0:
    print("Duplicate rows:")
    print(duplicates_specific_columns)
else:
    print("No duplicate rows found based on the specified columns.")

# 경고메세지 제거
import warnings
warnings.filterwarnings('ignore')

# library import
import numpy as np
import pandas as pd
import glob

# 시각화 library import
!pip install missingno
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns

#한글폰트 오류안나게
import matplotlib.pyplot as plt
from matplotlib import font_manager

# Use a system font that's available in Linux environments
# Replace 'NanumGothic' with any other system font if necessary
!apt-get update -qq
!apt-get install -qq fonts-nanum > /dev/null
font_fname = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf' # Use NanumGothic as an example

font_family = font_manager.FontProperties(fname=font_fname).get_name()
plt.rcParams['font.family'] = font_family

df_상품 = pd.read_csv('processed_dataset_dropped.csv')

df_상품.info()

# 제외할 조건 정의 (고객 접근성 제한이 심한 조건)
exclusion_conditions = [
    "전 금융기관을 통해 1인 1계좌에 한함",
    "외국인 비거주자는 증권투자전용 비거주자 원화계정을 통해서만 가능",
    "비거주자 제외",
    "가입조건(연령, 연소득, 무주택자 세대주)을\n충족하지 못할 경우",
]

# 필터링: 조건이 없거나 제외 조건에 해당하지 않는 경우만 남김
filtered_data = df_상품[
    (df_상품['가입제한_조건여부'] == '없음') |
    (df_상품['가입제한_조건'].isin(exclusion_conditions) & df_상품['가입제한_조건'].notna())
]

filtered_data.shape

# 기본금리 값 분포 확인
basic_rate_summary = df_상품['기본금리'].describe()
print(basic_rate_summary)

# 기본금리 히스토그램으로 시각화
import matplotlib.pyplot as plt
df_상품['기본금리'].hist(bins=20)
plt.title('기본금리 분포')
plt.xlabel('기본금리')
plt.ylabel('상품 수')
plt.show()

# 낮은 기본금리 기준 (1%)
low_rate_threshold = 1.0

# 기본금리가 낮거나 없는 상품 제외
filtered_data = filtered_data[
    (filtered_data['기본금리'] > low_rate_threshold) &
    (filtered_data['기본금리'].notna())
]

print(f"필터링 후 상품 수: {filtered_data.shape[0]}개")

filtered_data.info()

filtered_data.to_csv('df_회원_442.csv', index=False)

df_상품 = pd.read_csv('df_회원_442.csv')

# 기준 컬럼: 은행코드, 은행명, 상품코드, 상품명
key_columns = ['은행코드', '은행명', '상품코드', '상품명']

# 그룹화하여 동일한 키를 가진 행이 정확히 4개인 그룹만 필터링
step1_result = df_상품.groupby(key_columns).filter(lambda x: len(x) == 4)

print(f"같은 '은행코드, 은행명, 상품코드, 상품명'을 가진 그룹 중 4개의 행을 가진 데이터 수: {step1_result.shape[0]}")
step1_result

# 그룹핑
grouped = step1_result.groupby(key_columns)

# 그룹 내 다른 점 비교
def compare_differences(group):
    differences = {}
    for col in group.columns:
        if col not in key_columns:  # 기준 컬럼은 제외
            unique_values = group[col].unique()
            if len(unique_values) > 1:  # 값이 다르면 추가
                differences[col] = unique_values
    return differences

# 그룹별로 다른 점 추출
differences_by_group = grouped.apply(compare_differences)

# 결과 확인
for group, differences in differences_by_group.items():
    print(f"\n=== 그룹: {group} ===")
    for col, values in differences.items():
        print(f"{col}: {values}")

df_상품.info()

df_회원 = pd.read_csv('df_회원_필요칼럼.csv')

from joblib import Parallel, delayed
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import csr_matrix

# 가입금액 전처리 함수
def process_join_amount(value):
    try:
        if "제한없음" in value or "0원" in value:
            return 0
        if "백" in value:
            return float(value.replace("백", "").strip()) * 100
        if "천" in value:
            return float(value.replace("천", "").strip()) * 1000
        return float(value.replace("만원", "").split("~")[0].strip())
    except Exception:
        return None

# 회원별 상품 매칭 추천
def recommend_for_member(member, filtered_products):
    if filtered_products.empty:
        return []

    # 매칭 점수 계산
    filtered_products['매칭점수'] = (
        (filtered_products['가입대상고객_조건'].str.contains(str(member['Life_Stage']), na=False).astype(float)) * 0.5 +
        (filtered_products['processed_가입금액'] / member['총이용금액']) * 0.3 +
        (1 - member['연체비율']) * 0.2
    )
    return filtered_products.nlargest(3, '매칭점수')['상품명'].tolist()

# 병렬 처리 최적화
def recommend_parallel(df_회원_sample, df_상품, n_jobs=4):
    # 상품 데이터 전처리 (가입금액 한 번만 처리)
    df_상품['processed_가입금액'] = df_상품['가입금액'].apply(process_join_amount)

    # 회원별 필터링 및 추천 병렬 처리
    results = Parallel(n_jobs=n_jobs, backend='threading')(
        delayed(recommend_for_member)(member, df_상품) for _, member in df_회원_sample.iterrows()
    )
    return pd.DataFrame({
        "회원인덱스": df_회원_sample.index,
        "추천상품": results
    })

# 협업 필터링 최적화
def collaborative_filtering(interaction_matrix, member_id, top_n=3):
    interaction_sparse = csr_matrix(interaction_matrix.values)  # 희소 행렬 변환
    similarity_matrix = cosine_similarity(interaction_sparse)
    member_index = interaction_matrix.index.get_loc(member_id)
    similar_members = similarity_matrix[member_index].argsort()[-top_n-1:-1][::-1]
    recommended_products = interaction_matrix.iloc[similar_members].mean(axis=0).sort_values(ascending=False).index[:top_n].tolist()
    return recommended_products

# 실행
df_회원_sample = sample_members(df_회원, sample_size=1000)  # 회원 데이터 샘플링
interaction_matrix = prepare_interaction_matrix(df_회원_sample, df_상품)  # 상호작용 데이터 생성
n_jobs = 8

# 상품 매칭 추천 실행
df_추천결과 = recommend_parallel(df_회원_sample, df_상품, n_jobs=n_jobs)

# 협업 필터링 결과 추가
df_추천결과['협업_필터링_추천'] = df_추천결과['회원인덱스'].apply(
    lambda member_id: collaborative_filtering(interaction_matrix, member_id)
)

# 결과 확인
df_추천결과.head()

df_추천결과.to_csv('df_회원_1000_추천결과.csv', index=False)

from joblib import Parallel, delayed
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import csr_matrix

# 가입금액 전처리 함수
def process_join_amount(value):
    try:
        if "제한없음" in value or "0원" in value:
            return 0
        if "백" in value:
            return float(value.replace("백", "").strip()) * 100
        if "천" in value:
            return float(value.replace("천", "").strip()) * 1000
        return float(value.replace("만원", "").split("~")[0].strip())
    except Exception:
        return None

# 회원별 상품 매칭 추천
def recommend_for_member(member, filtered_products):
    if filtered_products.empty:
        return []

    # 매칭 점수 계산
    filtered_products['매칭점수'] = (
        (filtered_products['가입대상고객_조건'].str.contains(str(member['Life_Stage']), na=False).astype(float)) * 0.5 +
        (filtered_products['processed_가입금액'] / member['총이용금액']) * 0.3 +
        (1 - member['연체비율']) * 0.2
    )
    return filtered_products.nlargest(3, '매칭점수')['상품명'].tolist()

# 병렬 처리 최적화
def recommend_parallel(df_회원_sample, df_상품, n_jobs=4):
    # 상품 데이터 전처리 (가입금액 한 번만 처리)
    df_상품['processed_가입금액'] = df_상품['가입금액'].apply(process_join_amount)

    # 회원별 필터링 및 추천 병렬 처리
    results = Parallel(n_jobs=n_jobs, backend='threading')(
        delayed(recommend_for_member)(member, df_상품) for _, member in df_회원_sample.iterrows()
    )
    return pd.DataFrame({
        "회원인덱스": df_회원_sample.index,
        "추천상품": results
    })

# 협업 필터링 최적화
def collaborative_filtering(interaction_matrix, member_id, top_n=3):
    interaction_sparse = csr_matrix(interaction_matrix.values)  # 희소 행렬 변환
    similarity_matrix = cosine_similarity(interaction_sparse)
    member_index = interaction_matrix.index.get_loc(member_id)
    similar_members = similarity_matrix[member_index].argsort()[-top_n-1:-1][::-1]
    recommended_products = interaction_matrix.iloc[similar_members].mean(axis=0).sort_values(ascending=False).index[:top_n].tolist()
    return recommended_products

# 실행
df_회원_sample = sample_members(df_회원, sample_size=10000)  # 회원 데이터 샘플링
interaction_matrix = prepare_interaction_matrix(df_회원_sample, df_상품)  # 상호작용 데이터 생성
n_jobs = 8

# 상품 매칭 추천 실행
df_추천결과 = recommend_parallel(df_회원_sample, df_상품, n_jobs=n_jobs)

# 협업 필터링 결과 추가
df_추천결과['협업_필터링_추천'] = df_추천결과['회원인덱스'].apply(
    lambda member_id: collaborative_filtering(interaction_matrix, member_id)
)

# 결과 확인
df_추천결과.head()

df_추천결과.to_csv('df_회원_10000_추천결과.csv', index=False)

df_회원 = pd.read_csv('cluster_final.csv')

df_회원.info()

df_회원.head()

df_상품 = pd.read_csv('df_상품_442.csv')

# 남녀구분코드 -> 특정 상품이 남성 혹은 여성에게만 제공되거나 우대 조건에 성별이 포함될 수 있음.
# 연령 -> 연령대에 따라 상품 추천의 적합도가 달라짐.예) 청년 적금, 시니어 예금 등 연령 기반의 상품 조건.
# VIP등급코드-> VIP 등급에 따라 고급 금융 상품이나 특별 혜택 상품이 추천될 수 있음.
# 거주시도명 -> 지역 기반으로 제공되는 상품(특정 지역 한정 상품, 지역 우대 금리 등)에 필요.
# 직장시도명 -> 직장 위치에 따라 특정 지역이나 기업과 연계된 상품 추천 가능.
# 이용금액_R3M_신용 -> 최근 3개월 동안의 신용카드 이용 금액으로 소비 성향 파악. 예) 소비 성향이 높은 고객에게 고금리 적금 상품 추천.
# 이용금액_R3M_체크 -> 체크카드 사용량으로 금융 이용 패턴 파악. 예) 체크카드 선호 고객에게 수수료 면제 상품 추천.
# 총이용금액 ->전체 금융 이용 금액으로 소비력과 경제 수준을 평가. 예) 가입 금액이 높은 상품 추천 여부 결정.
# _1순위신용체크구분 -> 고객의 주 사용 카드 타입(신용/체크)을 파악. 예) 체크카드 선호 고객에게 관련 혜택 상품 추천.
# Life_Stage -> 고객의 생애 단계(청년, 중년, 노년 등)에 따라 상품 추천. 예)신혼부부 전용 적금, 은퇴자 전용 예금.
# 연체비율 -> 연체율이 낮은 고객에게 더 높은 금리나 혜택이 있는 상품 추천. 예) 신용 등급을 기준으로 맞춤형 상품 추천.
# 정규화_부유도 -> 고객의 부유도를 정규화하여 금융 상품을 추천. 예) 자산 관리 서비스, 고액 투자 상품 추천.
# 소지카드수_유효_신용 -> 보유 신용카드 수로 금융 서비스 선호도를 평가. 예) 신용카드 보유 수가 적은 고객에게 신규 발급 상품 추천.
# 유효카드수_체크 -> 체크카드 보유 수를 기반으로 소비 패턴 평가. 예) 체크카드 관련 적금이나 캐시백 혜택 상품 추천.
# 회원여부_연체 (추가 가능) -> 회원이 연체 중인지 여부로 신용 상태를 평가. 예) 연체 고객에게는 더 보수적인 상품 추천.

from joblib import Parallel, delayed
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import csr_matrix
import pandas as pd

# 가입금액 전처리 함수
def process_join_amount(value):
    try:
        if pd.isna(value) or "제한없음" in value or "0원" in value:
            return 0
        if "백" in value:
            return float(value.replace("백", "").strip()) * 100
        if "천" in value:
            return float(value.replace("천", "").strip()) * 1000
        if "만원" in value:
            return float(value.replace("만원", "").split("~")[0].strip()) * 10000
        return float(value)
    except Exception:
        return 0

# 추천 점수 계산 함수
def calculate_recommendation_score(member, product, weight_factors):
    life_stage_match = int(str(member['Life_Stage']) in str(product['가입대상고객_조건'])) * weight_factors['life_stage']
    join_amount_ratio = (product['processed_가입금액'] / (member['총이용금액'] + 1e-6)) * weight_factors['join_amount']
    delinquency_score = (1 - member['연체비율']) * weight_factors['delinquency']
    return life_stage_match + join_amount_ratio + delinquency_score

# 회원별 상품 추천 함수
def recommend_for_member(member, products, weight_factors, top_n=5):
    if products.empty:
        return []
    products['매칭점수'] = products.apply(lambda product: calculate_recommendation_score(member, product, weight_factors), axis=1)
    return products.nlargest(top_n, '매칭점수')['상품명'].tolist()

# 병렬 처리 추천 실행
def recommend_parallel(members, products, weight_factors, n_jobs=4, top_n=5):
    results = Parallel(n_jobs=n_jobs, backend='threading')(
        delayed(recommend_for_member)(member, products, weight_factors, top_n) for _, member in members.iterrows()
    )
    return pd.DataFrame({"회원인덱스": members.index, "추천상품": results})

# 협업 필터링 함수
def collaborative_filtering(interaction_matrix, member_id, top_n=3):
    try:
        interaction_sparse = csr_matrix(interaction_matrix.values)
        similarity_matrix = cosine_similarity(interaction_sparse)
        member_index = interaction_matrix.index.get_loc(member_id)
        similar_members = similarity_matrix[member_index].argsort()[-top_n-1:-1][::-1]
        recommended_products = interaction_matrix.iloc[similar_members].mean(axis=0).sort_values(ascending=False)
        return recommended_products.index[:top_n].tolist()
    except Exception:
        return []

# 상호작용 행렬 생성 함수
def prepare_interaction_matrix(df_members, df_products):
    interaction_data = df_members.merge(
        df_products, left_on='Life_Stage', right_on='가입대상고객_조건', how='inner'
    )
    interaction_matrix = interaction_data.pivot_table(
        index='Unnamed: 0', columns='상품명', values='구매횟수', fill_value=0
    )
    return interaction_matrix

# 실행 함수
def execute_recommendation(df_회원, df_상품, sample_size=1000, n_jobs=8, top_n=5):
    df_회원_sample = df_회원.sample(n=sample_size, random_state=42)
    df_상품['processed_가입금액'] = df_상품['가입금액'].apply(process_join_amount)
    weight_factors = {"life_stage": 0.5, "join_amount": 0.3, "delinquency": 0.2}
    df_추천결과 = recommend_parallel(df_회원_sample, df_상품, weight_factors, n_jobs=n_jobs, top_n=top_n)
    interaction_matrix = prepare_interaction_matrix(df_회원_sample, df_상품)
    df_추천결과['협력필터링_추천'] = df_추천결과['회원인덱스'].apply(
        lambda member_id: collaborative_filtering(interaction_matrix, member_id, top_n)
    )
    return df_추천결과

# df_회원 및 df_상품 데이터 준비
#df_회원 = pd.read_csv('path_to_회원.csv')  # 알려준 info 및 shape 기반 데이터 로드
#df_상품 = pd.read_csv('df_상품_442.csv')  # 업로드한 상품 데이터 사용

# 추천 실행
df_추천결과 = execute_recommendation(df_회원, df_상품, sample_size=1000, n_jobs=4, top_n=5)
print(df_추천결과)

# 경고메세지 제거
import warnings
warnings.filterwarnings('ignore')

# library import
import numpy as np
import pandas as pd
import glob

# 시각화 library import
!pip install missingno
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns

#한글폰트 오류안나게
import matplotlib.pyplot as plt
from matplotlib import font_manager

# Use a system font that's available in Linux environments
# Replace 'NanumGothic' with any other system font if necessary
!apt-get update -qq
!apt-get install -qq fonts-nanum > /dev/null
font_fname = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf' # Use NanumGothic as an example

font_family = font_manager.FontProperties(fname=font_fname).get_name()
plt.rcParams['font.family'] = font_family

# 우대금리사항 제외한 칼럼
df_상품 = pd.read_csv('processed_dataset_dropped.csv')
# 필요 칼럼만 가져옴
# necessary_columns = [
#    '남녀구분코드', '연령', 'VIP등급코드', '거주시도명', '직장시도명',
#    '이용금액_R3M_신용', '이용금액_R3M_체크', '총이용금액', '_1순위신용체크구분',
#    'Life_Stage', '연체비율', '정규화_부유도', '소지카드수_유효_신용',
#    '유효카드수_체크', '회원여부_연체'
#]
df_회원 = pd.read_csv('df_회원_필요칼럼.csv')

# 상품추천 알고리즘
from joblib import Parallel, delayed

# 가입금액 전처리 함수 정의
def process_join_amount(value):
    try:
        if "제한없음" in value or "0원" in value:
            return 0
        if "백" in value:
            return float(value.replace("백", "").strip()) * 100
        if "천" in value:
            return float(value.replace("천", "").strip()) * 1000
        return float(value.replace("만원", "").split("~")[0].strip())
    except Exception:
        return None

# 상품 필터링 및 추천 함수 (회원 단위 처리)
def recommend_for_member(member, df_상품):
    filtered_products = df_상품[
        df_상품['가입대상고객_조건'].str.contains(str(member['Life_Stage']), na=False)
    ]
    filtered_products = filtered_products[
        (filtered_products['processed_가입금액'] <= member['총이용금액']) |
        (filtered_products['processed_가입금액'].isnull())
    ]
    filtered_products = filtered_products[
        filtered_products['기타_상품가입_고려사항'].str.contains(member['거주시도명'], na=False)
    ]

    ## 필터 했을 때, 나오는 결과 확인
    ## 샘플링 처럼 부분적 코딩 => 랜덤하게 샘플링
    ## 콜라보레이티브 필터링 / (추천 시스템) 협업 필터링


    filtered_products['매칭점수'] = (
        (filtered_products['가입대상고객_조건'].str.contains(str(member['Life_Stage']), na=False).astype(float)) * 0.5 +
        (filtered_products['processed_가입금액'] / member['총이용금액']) * 0.3 +
        (1 - member['연체비율']) * 0.2
    )

    filtered_products['매칭점수'] = filtered_products['매칭점수'].astype(float)
    top_products = filtered_products.nlargest(3, '매칭점수')

    return {
        '회원인덱스': member.name,
        '추천상품': top_products['상품명'].tolist()
    }

# 전체 회원 데이터를 병렬로 처리
def recommend_parallel(df_회원, df_상품, n_jobs=4):
    df_상품['processed_가입금액'] = df_상품['가입금액'].apply(process_join_amount)
    results = Parallel(n_jobs=n_jobs, backend='multiprocessing')(
        delayed(recommend_for_member)(member, df_상품) for _, member in df_회원.iterrows()
    )
    return pd.DataFrame(results)

# 병렬 처리 실행
n_jobs = 8  # 사용 가능한 CPU 코어 수 지정
df_추천결과 = recommend_parallel(df_회원, df_상품, n_jobs=n_jobs)

# 추천 결과 확인
df_추천결과.head()

# 추천 결과를 CSV로 저장
output_path = "추천결과.csv"  # 저장할 파일 경로
df_추천결과.to_csv(output_path, index=False)

print(f"추천 결과가 '{output_path}' 파일로 저장되었습니다.")

df_추천 = pd.read_csv('추천결과.csv')

df_추천.head()

